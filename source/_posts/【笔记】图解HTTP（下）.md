---
title: 【笔记】图解HTTP（下）
abbrlink: cdaa17bd
date: 2022-04-04 16:34:13
updated: 2022-04-04 16:34:13
description: 虽然现在都用2.0了，但是看1.1也不算过时吧？
index_img: /image/图解HTTP/index.jpg
banner_img: /image/图解HTTP/banner.jpg
tags:
  - 基础体系
categories: 笔记
---

## 第七章 确保Web安全的HTTPS

### 7.1 HTTP的缺点

- HTTP主要有这些不足，例举如下（这些问题不仅在HTTP上出现，其他未加密的协议中也会存在这类问题）

  - 通信使用明文（不加密），内容可能会被窃听

  - 不验证通信方的身份，因此有可能遭遇伪装

  - 无法证明报文的完整性，所以有可能已遭篡改

- 除此之外，HTTP本身还有很多缺点。而且，还有像某些特定的Web服务器和特定的Web浏览器在实际应用中存在的不足（也可以说成是脆弱性或安全漏洞），另外，用Java和PHP等编程语言开发的Web应用也可能存在安全漏洞

#### 7.1.1 通信使用明文可能会被窃听

- 由于HTTP本身不具备加密的功能，所以也无法做到对通信整体（使用HTTP协议通信的请求和响应的内容）进行加密。即，HTTP报文使用明文（指未经过加密的报文）方式发送

- TCP/IP是可能被窃听的网络

  - 如果要问为什么通信时不加密是一个缺点，这是因为，按TCP/IP协议族的工作机制，通信内容在所有的通信线路上都有可能遭到窥视

  - 所谓互联网，是由能连通到全世界的网络组成的。无论世界哪个角落的服务器在和客户端通信时，在此通信线路上的某些网络设备、光缆、计算机等都不可能是个人的私有物，所以不排除某个环节中会遭到恶意窥视行为

  - 即使已经过加密处理的通信，也会被窥视到通信内容，这点和未加密的通信是相同的。只是说如果通信经过加密，就有可能让人无法破解报文信息的含义，但加密处理后的报文信息本身还是会被看到的

  - 窃听相同段上的通信并非难事。只需要收集在互联网上流动的数据包（帧）就行了。对于收集来的数据包的解析工作，可交给那些抓包（Packet Capture）或嗅探器（Sniffer）工具

- 加密处理可以防止被窃听，在目前大家正在研究的如何防止窃听保护信息的几种对策中，最为普及的就是加密技术。加密的对象可以有这么几个

  - 通信的加密

    ![epub_907764_163.jpeg](/image/图解HTTP/cd1b66ee5dd195a2de74b236785127ee0bf4b899.jpeg)

    - 一种方式就是将通信加密
    - HTTP协议中没有加密机制，但可以通过和SSL（Secure Socket Layer，安全套接层）或TLS（Transport LayerSecurity，安全传输层协议）的组合使用，加密HTTP的通信内容。用SSL建立安全通信线路之后，就可以在这条线路上进行HTTP通信了
    - 与SSL组合使用的HTTP被称为HTTPS（HTTP Secure，超文本传输安全协议）或HTTP over SSL

  - 内容的加密

    ![epub_907764_164.jpeg](/image/图解HTTP/cb3ffdba1c9cf383c9c967819ee6e4a75fc5aacf.jpeg)

    - 还有一种将参与通信的内容本身加密的方式
    - 由于HTTP协议中没有加密机制，那么就对HTTP协议传输的内容本身加密。即把HTTP报文里所含的内容进行加密处理
    - 在这种情况下，客户端需要对HTTP报文进行加密处理后再发送请求
    - 诚然，为了做到有效的内容加密，前提是要求客户端和服务器同时具备加密和解密机制
    - 有一点必须引起注意，由于该方式不同于SSL或TLS将整个通信线路加密处理，所以内容仍有被篡改的风险。稍后我们会加以说明

#### 7.1.2 不验证通信方的身份就可能遭遇伪装

- HTTP协议中的请求和响应不会对通信方进行确认。也就是说存在“服务器是否就是发送请求中URI真正指定的主机，返回的响应是否真的返回到实际提出请求的客户端”等类似问题

- 在HTTP协议通信时，由于不存在确认通信方的处理步骤，任何人都可以发起请求。另外，服务器只要接收到请求，不管对方是谁都会返回一个响应（但也仅限于发送端的IP地址和端口号没有被Web服务器设定限制访问的前提下）

- HTTP协议的实现本身非常简单，不论是谁发送过来的请求都会返回响应，因此不确认通信方，会存在以下各种隐患

  - 无法确定请求发送至目标的Web服务器是否是按真实意图返回响应的那台服务器。有可能是已伪装的Web服务器

  - 无法确定响应返回到的客户端是否是按真实意图接收响应的那个客户端。有可能是已伪装的客户端

  - 无法确定正在通信的对方是否具备访问权限。因为某些Web服务器上保存着重要的信息，只想发给特定用户通信的权限

  - 无法判定请求是来自何方、出自谁手

  - 即使是无意义的请求也会照单全收。无法阻止海量请求下的DoS攻击（Denial of Service，拒绝服务攻击）

- 查明对手的证书

  - 虽然使用HTTP协议无法确定通信方，但如果使用SSL则可以。SSL不仅提供加密处理，而且还使用了一种被称为证书的手段，可用于确定方

  - 证书由值得信任的第三方机构颁发，用以证明服务器和客户端是实际存在的。另外，伪造证书从技术角度来说是异常困难的一件事。所以只要能够确认通信方（服务器或客户端）持有的证书，即可判断通信方的真实意图

  - 通过使用证书，以证明通信方就是意料中的服务器。这对使用者个人来讲，也减少了个人信息泄露的危险性

  - 另外，客户端持有证书即可完成个人身份的确认，也可用于对Web网站的认证环节

#### 7.1.3 无法证明报文完整性，可能已遭篡改

- 所谓完整性是指信息的准确度。若无法证明其完整性，通常也就意味着无法判断信息是否准确

- 接收到的内容可能有误

  - 由于HTTP协议无法证明通信的报文完整性，因此，在请求或响应送出之后直到对方接收之前的这段时间内，即使请求或响应的内容遭到篡改，也没有办法获悉

  - 换句话说，没有任何办法确认，发出的请求/响应和接收到的请求/响应是前后相同的

  - 比如，从某个Web网站上下载内容，是无法确定客户端下载的文件和服务器上存放的文件是否前后一致的。文件内容在传输途中可能已经被篡改为其他的内容。即使内容真的已改变，作为接收方的客户端也是觉察不到的

  - 像这样，请求或响应在传输途中，遭攻击者拦截并篡改内容的攻击称为中间人攻击（Man-in-the-Middle attack,MITM）

- 如何防止篡改

  - 虽然有使用HTTP协议确定报文完整性的方法，但事实上并不便捷、可靠。其中常用的是MD5和SHA-1等散列值校验的方法，以及用来确认文件的数字签名方法

  - 提供文件下载服务的Web网站也会提供相应的以PGP（Pretty GoodPrivacy，完美隐私）创建的数字签名及MD5算法生成的散列值

    - PGP是用来证明创建文件的数字签名，MD5是由单向函数生成的散列值

    - 不论使用哪一种方法，都需要操纵客户端的用户本人亲自检查验证下载的文件是否就是原来服务器上的文件。浏览器无法自动帮用户检查

  - 可惜的是，用这些方法也依然无法百分百保证确认结果正确。因为PGP和MD5本身被改写的话，用户是没有办法意识到的

- 为了有效防止这些弊端，有必要使用HTTPS。SSL提供认证和加密处理及摘要功能。仅靠HTTP确保完整性是非常困难的，因此通过和其他协议组合使用来实现这个目标

### 7.2 HTTP+加密+认证+完整性保护=HTTPS

#### 7.2.1 HTTP加上加密处理和认证以及完整性保护后即是HTTPS

- 为了统一解决窃听和篡改这些问题，需要在HTTP上再加入加密处理和认证等机制。我们把添加了加密及认证机制的HTTP称为HTTPS（HTTP Secure）

  - 如果在HTTP协议通信过程中使用未经加密的明文，比如在Web页面中输入信用卡号，如果这条通信线路遭到窃听，那么信用卡号就暴露了

  - 另外，对于HTTP来说，服务器也好，客户端也好，都是没有办法确认通信方的。因为很有可能并不是和原本预想的通信方在实际通信。并且还需要考虑到接收到的报文在通信途中已经遭到篡改这一可能性

- 使用HTTPS通信时，不再用http://，而是改用https://。另外，当浏览器访问HTTPS通信有效的Web网站时，浏览器的地址栏内会出现一个带锁的标记。对HTTPS的显示方式会因浏览器的不同而有所改变

#### 7.2.2 HTTPS是身披SSL外壳的HTTP

- HTTPS并非是应用层的一种新协议。只是HTTP通信接口部分用SSL（SecureSocket Layer）和TLS（Transport Layer Security）协议代替而已

- 通常，HTTP直接和TCP通信。当使用SSL时，则演变成先和SSL通信，再由SSL和TCP通信了。简言之，所谓HTTPS，其实就是身披SSL协议这层外壳的HTTP

  ![epub_907764_172.jpeg](/image/图解HTTP/08ce162fc302af3d09cab6d774dee5072c6f0abe.jpeg)

- 在采用SSL后，HTTP就拥有了HTTPS的加密、证书和完整性保护这些功能

- SSL是独立于HTTP的协议，所以不光是HTTP协议，其他运行在应用层的SMTP和Telnet等协议均可配合SSL协议使用。可以说SSL是当今世界上应用最为广泛的网络安全技术

#### 7.2.3 相互交换密钥的公开密钥加密技术

- SSL采用一种叫做公开密钥加密（Public-key cryptography）的加密处理方式

  - 近代的加密方法中加密算法是公开的，而密钥却是保密的。通过这种方式得以保持加密方法的安全性

  - 加密和解密都会用到密钥。没有密钥就无法对密码解密，反过来说，任何人只要持有密钥就能解密了。如果密钥被攻击者获得，那加密也就失去了意义

- 共享密钥加密的困境

  - 加密和解密同用一个密钥的方式称为共享密钥加密（Common key cryptosystem），也被叫做对称密钥加密

  - 以共享密钥方式加密时必须将密钥也发给对方。可究竟怎样才能安全地转交？在互联网上转发密钥时，如果通信被监听那么密钥就可会落入攻击者之手，同时也就失去了加密的意义。另外还得设法安全地保管接收到的密钥

- 使用两把密钥的公开密钥加密

  - 公开密钥加密方式很好地解决了共享密钥加密的困难。公开密钥加密使用一对非对称的密钥。一把叫做私有密钥（private key），另一把叫做公开密钥（public key）。顾名思义，私有密钥不能让其他任何人知道，而公开密钥则可以随意发布，任何人都可以获得

  - 使用公开密钥加密方式，发送密文的一方使用对方的公开密钥进行加密处理，对方收到被加密的信息后，再使用自己的私有密钥进行解密。利用这种方式，不需要发送用来解密的私有密钥，也不必担心密钥被攻击者窃听而盗走

  - 另外，要想根据密文和公开密钥，恢复到信息原文是异常困难的，因为解密过程就是在对离散对数进行求值，这并非轻而易举就能办到。退一步讲，如果能对一个非常大的整数做到快速地因式分解，那么密码破解还是存在希望的。但就目前的技术来看是不太现实的

- HTTPS采用混合加密机制

  - HTTPS采用共享密钥加密和公开密钥加密两者并用的混合加密机制

    - 若密钥能够实现安全交换，那么有可能会考虑仅使用公开密钥加密来通信。但是公开密钥加密与共享密钥加密相比，其处理速度要慢

  - HTTPS充分利用两者各自的优势，将多种方法组合起来用于通信。在交换密钥环节使用公开密钥加密方式，之后的建立通信交换报文阶段则使用共享密钥加密方式

  - 混合加密机制

    ![epub_907764_176.jpeg](/image/图解HTTP/b1283b222cf4fb4e047be231871b8bab593b6a6d.jpeg)

#### 7.2.4 证明公开密钥正确性的证书

- 遗憾的是，公开密钥加密方式还是存在一些问题的。那就是无法证明公开密钥本身就是货真价实的公开密钥

  - 比如，正准备和某台服务器建立公开密钥加密方式下的通信时，如何证明收到的公开密钥就是原本预想的那台服务器发行的公开密钥。或许在公开密钥传输途中，真正的公开密钥已经被攻击者替换掉了

  - 为了解决上述问题，可以使用由数字证书认证机构（CA,CertificateAuthority）和其相关机关颁发的公开密钥证书

- 数字证书认证机构处于客户端与服务器双方都可信赖的第三方机构的立场上。威瑞信（VeriSign）就是其中一家非常有名的数字证书认证机构

- 数字证书认证机构的业务流程

  - 首先，服务器的运营人员向数字证书认证机构提出公开密钥的申请

  - 数字证书认证机构在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公钥证书后绑定在一起

  - 然后服务器会将这份由数字证书认证机构颁发的公钥证书发送给客户端，以进行公开密钥加密方式通信。公钥证书也可叫做数字证书或直接称为证书

  - 接到证书的客户端可使用数字证书认证机构的公开密钥，对那张证书上的数字签名进行验证，一旦验证通过，客户端便可明确两件事

    - 一，认证服务器的公开密钥的是真实有效的数字证书认证机构

    - 二，服务器的公开密钥是值得信赖的

  - 此处认证机关的公开密钥必须安全地转交给客户端。使用通信方式时，如何安全转交是一件很困难的事，因此，多数浏览器开发商发布版本时，会事先在内部植入常用认证机关的公开密钥

- 数字证书认证机构的业务流程示意图

  ![epub_907764_177.jpeg](/image/图解HTTP/328cb6a376336530bb68d7ee02a4e8034a47509e.jpeg)

- [RSA的公钥和私钥到底哪个才是用来加密和哪个用来解密？](https://www.zhihu.com/question/25912483)

- 可证明组织真实性的EV SSL证书

  - 证书的一个作用是用来证明作为通信一方的服务器是否规范，另外一个作用是可确认对方服务器背后运营的企业是否真实存在。拥有该特性的证书就是EVSSL证书（Extended Validation SSL Certificate）

  - EV SSL证书是基于国际标准的认证指导方针颁发的证书。其严格规定了对运营组织是否真实的确认方针，因此，通过认证的Web网站能够获得更高的认可度

- 用以确认客户端的客户端证书

  - HTTPS中还可以使用客户端证书。以客户端证书进行客户端认证，证明服务器正在通信的对方始终是预料之内的客户端，其作用跟服务器证书如出一辙

- 客户端证书仍存在几处问题点

  - 其中的一个问题点是证书的获取及发布

    - 想获取证书时，用户得自行安装客户端证书。但由于客户端证书是要付费购买的，且每张证书对应到每位用户也就意味着需支付和用户数对等的费用

    - 另外，要让知识层次不同的用户们自行安装证书，这件事本身也充满了各种挑战

    - 现状是，安全性极高的认证机构可颁发客户端证书但仅用于特殊用途的业务。比如那些可支撑客户端证书支出费用的业务。例如，银行的网上银行就采用了客户端证书。在登录网银时不仅要求用户确认输入ID和密码，还会要求用户的客户端证书，以确认用户是否从特定的终端访问网银

  - 客户端证书存在的另一个问题点是，客户端证书毕竟只能用来证明客户端实际存在，而不能用来证明用户本人的真实有效性。也就是说，只要获得了安装有客户端证书的计算机的使用权限，也就意味着同时拥有了客户端证书的使用权限

- 认证机构信誉第一

  - SSL机制中介入认证机构之所以可行，是因为建立在其信用绝对可靠这一大前提下的

    - 然而，2011年7月，荷兰的一家名叫DigiNotar的认证机构曾遭黑客不法入侵，颁布了google.com和twitter.com等网站的伪造证书事件。这一事件从根本上撼动了SSL的可信度

  - 因为伪造证书上有正规认证机构的数字签名，所以浏览器会判定该证书是正当的。当伪造的证书被用做服务器伪装之时，用户根本无法察觉到

  - 虽然存在可将证书无效化的证书吊销列表（Certificate RevocationList,CRL）机制，以及从客户端删除根证书颁发机构（Root CertificateAuthority,RCA）的对策，但是距离生效还需要一段时间，而在这段时间内，到底会有多少用户的利益蒙受损失就不得而知了

- 由自认证机构颁发的证书称为自签名证书

  - 如果使用OpenSSL这套开源程序，每个人都可以构建一套属于自己的认证机构，从而自己给自己颁发服务器证书。但该服务器证书在互联网上不可作为证书使用，似乎没什么帮助

  - 独立构建的认证机构叫做自认证机构，由自认证机构颁发的“无用”证书也被戏称为自签名证书

  - 浏览器访问该服务器时，会显示“无法确认连接安全性”或“该网站的安全证书存在问题”等警告消息

  - 由自认证机构颁发的服务器证书之所以不起作用，是因为它无法消除伪装的可能性。自认证机构能够产生的作用顶多也就是自己对外宣称“我是○○”的这种程度。即使采用自签名证书，通过SSL加密之后，可能偶尔还会看见通信处在安全状态的提示，可那也是有问题的。因为就算加密通信，也不能排除正在和已经过伪装的假服务器保持通信

  - 值得信赖的第三方机构介入认证，才能让已植入在浏览器内的认证机构颁布的公开密钥发挥作用，并借此证明服务器的真实性

  - 中级认证机构的证书可能会变成自认证证书

    - 多数浏览器内预先已植入备受信赖的认证机构的证书，但也有一小部分浏览器会植入中级认证机构的证书

    - 对于中级认证机构颁发的服务器证书，某些浏览器会以正规的证书来对待，可有的浏览器会当作自签名证书

#### 7.2.5 HTTPS的安全通信机制

- HTTPS的通信步骤示意图

  ![epub_907764_181.jpeg](/image/图解HTTP/8a54ed4c911a400389078b93383040f467703a4f.jpeg)

- HTTPS的通信步骤

  - 步骤1：客户端通过发送Client Hello报文开始SSL通信。报文中包含客户端支持的SSL的指定版本、加密组件（Cipher Suite）列表（所使用的加密算法及密钥长度等）

  - 步骤2：服务器可进行SSL通信时，会以Server Hello报文作为应答。和客户端一样，在报文中包含SSL版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的

  - 步骤3：之后服务器发送Certificate报文。报文中包含公开密钥证书

  - 步骤4：最后服务器发送Server Hello Done报文通知客户端，最初阶段的SSL握手协商部分结束

  - 步骤5：SSL第一次握手结束之后，客户端以Client Key Exchange报文作为回应。报文中包含通信加密中使用的一种被称为Pre-master secret的随机密码串。该报文已用步骤3中的公开密钥进行加密

  - 步骤6：接着客户端继续发送Change Cipher Spec报文。该报文会提示服务器，在此报文之后的通信会采用Pre-master secret密钥加密

  - 步骤7：客户端发送Finished报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准

  - 步骤8：服务器同样发送Change Cipher Spec报文

  - 步骤9：服务器同样发送Finished报文

  - 步骤10：服务器和客户端的Finished报文交换完毕之后，SSL连接就算建立完成。当然，通信会受到SSL的保护。从此处开始进行应用层协议的通信，即发送HTTP请求

  - 步骤11：应用层协议通信，即发送HTTP响应

  - 步骤12：最后由客户端断开连接。断开连接时，发送close_notify报文。上图做了一些省略，这步之后再发送TCP FIN报文来关闭与TCP的通信

- 在以上流程中，应用层发送数据时会附加一种叫做MAC（MessageAuthentication Code）的报文摘要。MAC能够查知报文是否遭到篡改，从而保护报文的完整性

- 下面是对整个流程的图解。图中说明了从仅使用服务器端的公开密钥证书（服务器证书）建立HTTPS通信的整个过程

  ![epub_907764_182.jpeg](/image/图解HTTP/8fe626de0c86d600f3132156f627b0bb10224468.jpeg)

  - CBC模式（Cipher Block Chaining）又名密码分组链接模式。在此模式下，将前一个明文块加密处理后和下一个明文块做XOR运算，使之重叠，然后再对运算结果做加密处理。对第一个明文块做加密时，要么使用前一段密文的最后一块，要么利用外部生成的初始向量（initial vector,IV）。——译者注

- SSL和TLS

  - HTTPS使用SSL（Secure Socket Layer）和TLS（Transport LayerSecurity）这两个协议

  - SSL技术最初是由浏览器开发商网景通信公司率先倡导的，开发过SSL3.0之前的版本。目前主导权已转移到IETF（Internet Engineering TaskForce,Internet工程任务组）的手中

  - IETF以SSL3.0为基准，后又制定了TLS1.0、TLS1.1和TLS1.2。TSL是以SSL为原型开发的协议，有时会统一称该协议为SSL。当前主流的版本是SSL3.0和TLS1.0

  - 由于SSL1.0协议在设计之初被发现出了问题，就没有实际投入使用。SSL2.0也被发现存在问题，所以很多浏览器直接废除了该协议版本

- HTTPS也存在一些问题，那就是当使用SSL时，它的处理速度会变慢

  - SSL的慢分两种。一种是指通信慢。另一种是指由于大量消耗CPU及内存等资源，导致处理速度变慢

  - 和使用HTTP相比，网络负载可能会变慢2到100倍。除去和TCP连接、发送HTTP请求/响应以外，还必须进行SSL通信，因此整体上处理通信量不可避免会增加

  - 另一点是SSL必须进行加密处理。在服务器和客户端都需要进行加密和解密的运算处理。因此从结果上讲，比起HTTP会更多地消耗服务器和客户端的硬件资源，导致负载增强

  - 针对速度变慢这一问题，并没有根本性的解决方案，我们会使用SSL加速器这种（专用服务器）硬件来改善该问题。该硬件为SSL通信专用硬件，相对软件来讲，能够提高数倍SSL的计算速度。仅在SSL处理时发挥SSL加速器的功效，以分担负载

- 既然HTTPS那么安全可靠，那为何所有的Web网站不一直使用HTTPS？

  - 其中一个原因是，因为与纯文本通信相比，加密通信会消耗更多的CPU及内存资源

    - 如果每次通信都加密，会消耗相当多的资源，平摊到一台计算机上时，能够处理的请求数量必定也会随之减少

    - 因此，如果是非敏感信息则使用HTTP通信，只有在包含个人信息等敏感数据时，才利用HTTPS加密通信

    - 特别是每当那些访问量较多的Web网站在进行加密处理时，它们所承担着的负载不容小觑

    - 在进行加密处理时，并非对所有内容都进行加密处理，而是仅在那些需要信息隐藏时才会加密，以节约资源

  - 除此之外，想要节约购买证书的开销也是原因之一

    - 要进行HTTPS通信，证书是必不可少的。而使用的证书必须向认证机构（CA）购买。证书价格可能会根据不同的认证机构略有不同

    - 那些购买证书并不合算的服务以及一些个人网站，可能只会选择采用HTTP的通信方式

## 第八章 确认访问用户身份的认证

### 8.1 何为认证

- 计算机本身无法判断坐在显示器前的使用者的身份。进一步说，也无法确认网络的那头究竟有谁。可见，为了弄清究竟是谁在访问服务器，就得让对方的客户端自报家门

- 可是，就算正在访问服务器的对方声称自己是ueno，身份是否属实这点却也无从谈起。为确认ueno本人是否真的具有访问系统的权限，就需要核对“登录者本人才知道的信息”、“登录者本人才会有的信息”

- 核对的信息通常是指以下这些

  - 密码：只有本人才会知道的字符串信息

  - 动态令牌：仅限本人持有的设备内显示的一次性密码

  - 数字证书：仅限本人（终端）持有的信息

  - 生物认证：指纹和虹膜等本人的生理信息

  - IC卡等：仅限本人持有的信息

- 但是，即便对方是假冒的用户，只要能通过用户验证，那么计算机就会默认是出自本人的行为。因此，掌控机密信息的密码绝不能让他人得到，更不能轻易地就被破解出来

- HTTP/1.1使用的认证方式如下所示

  - BASIC认证（基本认证）

  - DIGEST认证（摘要认证）

  - SSL客户端认证

  - FormBase认证（基于表单认证）

- 此外，还有Windows统一认证（Keberos认证、NTLM认证），但本书不作讲解

#### 8.2 BASIC认证

- BASIC认证（基本认证）是从HTTP/1.0就定义的认证方式。即便是现在仍有一部分的网站会使用这种认证方式。是Web服务器与通信客户端之间进行的认证方式

- BASIC认证的认证步骤示意图

  ![epub_907764_187.jpeg](/image/图解HTTP/a046dd02432af0a827e6bcfbd55eaf27f7432c76.jpeg)

- BASIC认证的认证步骤

  - 步骤1：当请求的资源需要BASIC认证时，服务器会随状态码401Authorization Required，返回带WWW-Authenticate首部字段的响应。该字段内包含认证的方式（BASIC）及Request-URI安全域字符串（realm）

  - 步骤2：接收到状态码401的客户端为了通过BASIC认证，需要将用户ID及密码发送给服务器。发送的字符串内容是由用户ID和密码构成，两者中间以冒号（:）连接后，再经过Base64编码处理

  - 步骤3：接收到包含首部字段Authorization请求的服务器，会对认证信息的正确性进行验证。如验证通过，则返回一条包含Request-URI资源的响应

- BASIC认证虽然采用Base64编码方式，但这不是加密处理。不需要任何附加信息即可对其解码。换言之，由于明文解码后就是用户ID和密码，在HTTP等非加密通信的线路上进行BASIC认证的过程中，如果被人窃听，被盗的可能性极高

- 另外，除此之外想再进行一次BASIC认证时，一般的浏览器却无法实现认证注销操作，这也是问题之一

- BASIC认证使用上不够便捷灵活，且达不到多数Web网站期望的安全性等级，因此它并不常用

### 8.3 DIGEST认证

- 为弥补BASIC认证存在的弱点，从HTTP/1.1起就有了DIGEST认证。DIGEST认证同样使用质询/响应的方式（challenge/response），但不会像BASIC认证那样直接发送明文密码

- 所谓质询响应方式是指，一开始一方会先发送认证要求给另一方，接着使用从另一方那接收到的质询码计算生成响应码。最后将响应码返回给对方进行认证的方式。因为发送给对方的只是响应摘要及由质询码产生的计算结果，所以比起BASIC认证，密码泄露的可能性就降低了

- DIGEST认证的认证步骤示意图

  ![epub_907764_190.jpeg](/image/图解HTTP/0335941db02beca1a1ea8bc27355c27bce8ee66b.jpeg)

- DIGEST认证的认证步骤

  - 步骤1：请求需认证的资源时，服务器会随着状态码401 AuthorizationRequired，返回带WWW-Authenticate首部字段的响应

    - 该字段内包含质问响应方式认证所需的临时质询码（随机数，nonce）

    - 首部字段WWW-Authenticate内必须包含realm和nonce这两个字段的信息。客户端就是依靠向服务器回送这两个值进行认证的

    - nonce是一种每次随返回的401响应生成的任意随机字符串。该字符串通常推荐由Base64编码的十六进制数的组成形式，但实际内容依赖服务器的具体实现

  - 步骤2： 接收到401状态码的客户端，返回的响应中包含DIGEST认证必须的首部字段Authorization信息

    - 首部字段Authorization内必须包含username、realm、nonce、uri和response的字段信息

    - 其中，realm和nonce就是之前从服务器接收到的响应中的字段。username是realm限定范围内可进行认证的用户名

    - uri（digest-uri）即Request-URI的值，但考虑到经代理转发后Request-URI的值可能被修改，因此事先会复制一份副本保存在uri内

    - response也可叫做Request-Digest，存放经过MD5运算后的密码字符串，形成响应码

    - 响应中其他的实体请参见第6章的请求首部字段Authorization。另外，有关Request-Digest的计算规则较复杂，有兴趣的读者不妨深入学习一下RFC2617

  - 步骤3：接收到包含首部字段Authorization请求的服务器，会确认认证信息的正确性。认证通过后则返回包含Request-URI资源的响应。并且这时会在首部字段Authentication-Info写入一些认证成功的相关信息

- DIGEST认证提供了高于BASIC认证的安全等级，但是和HTTPS的客户端认证相比仍旧很弱。DIGEST认证提供防止密码被窃听的保护机制，但并不存在防止用户伪装的保护机制。DIGEST认证和BASIC认证一样，使用上不那么便捷灵活，且仍达不到多数Web网站对高度安全等级的追求标准。因此它的适用范围也有所受限

### 8.4 SSL客户端认证

- 从使用用户ID和密码的认证方式方面来讲，只要二者的内容正确，即可认证是本人的行为。但如果用户ID和密码被盗，就很有可能被第三者冒充。利用SSL客户端认证则可以避免该情况的发生

- SSL客户端认证是借由HTTPS的客户端证书完成认证的方式。凭借客户端证书（在HTTPS一章已讲解）认证，服务器可确认访问是否来自已登录的客户端

- SSL客户端认证的认证步骤

  - 为达到SSL客户端认证的目的，需要事先将客户端证书分发给客户端，且客户端必须安装此证书

  - 步骤1：接收到需要认证资源的请求，服务器会发送Certificate Request报文，要求客户端提供客户端证书

  - 步骤2：用户选择将发送的客户端证书后，客户端会把客户端证书信息以Client Certificate报文方式发送给服务器

  - 步骤3：服务器验证客户端证书验证通过后方可领取证书内客户端的公开密钥，然后开始HTTPS加密通信

- SSL客户端认证采用双因素认证

  - 在多数情况下，SSL客户端认证不会仅依靠证书完成认证，一般会和基于表单认证（稍后讲解）组合形成一种双因素认证（Two-factor authentication）来使用

  - 所谓双因素认证就是指，认证过程中不仅需要密码这一个因素，还需要申请认证者提供其他持有信息，从而作为另一个因素，与其组合使用的认证方式

  - 换言之，第一个认证因素的SSL客户端证书用来认证客户端计算机，另一个认证因素的密码则用来确定这是用户本人的行为

  - 通过双因素认证后，就可以确认是用户本人正在使用匹配正确的计算机访问服务器

- SSL客户端认证必要的费用

  - 使用SSL客户端认证需要用到客户端证书。而客户端证书需要支付一定费用才能使用

  - 这里提到的费用是指，从认证机构购买客户端证书的费用，以及服务器运营者为保证自己搭建的认证机构安全运营所产生的费用

  - 每个认证机构颁发客户端证书的费用不尽相同，平摊到一张证书上，一年费用约几万至十几万日元。服务器运营者也可以自己搭建认证机构，但要维持安全运行就会产生相应的费用

### 8.5 基于表单认证

- 基于表单的认证方法并不是在HTTP协议中定义的。客户端会向服务器上的Web应用程序发送登录信息（Credential），按登录信息的验证结果认证

- 根据Web应用程序的实际安装，提供的用户界面及认证方式也各不相同。多数情况下，输入已事先登录的用户ID（通常是任意字符串或邮件地址）和密码等登录信息后，发送给Web应用程序，基于认证结果来决定认证是否成功

#### 8.5.1 认证多半为基于表单认证

- 由于使用上的便利性及安全性问题，HTTP协议标准提供的BASIC认证和DIGEST认证几乎不怎么使用。另外，SSL客户端认证虽然具有高度的安全等级，但因为导入及维持费用等问题，还尚未普及

- 比如SSH和FTP协议，服务器与客户端之间的认证是合乎标准规范的，并且满足了最基本的功能需求上的安全使用级别，因此这些协议的认证可以拿来直接使用。但是对于Web网站的认证功能，能够满足其安全使用级别的标准规范并不存在，所以只好使用由Web应用程序各自实现基于表单的认证方式

- 不具备共同标准规范的表单认证，在每个Web网站上都会有各不相同的实现方式。如果是全面考虑过安全性能而实现的表单认证，那么就能够具备高度的安全等级。但在表单认证的实现中存在问题的Web网站也是屡见不鲜

#### 8.5.2 Session管理及Cookie应用

- 基于表单认证的标准规范尚未有定论，一般会使用Cookie来管理Session（会话）

- 基于表单认证本身是通过服务器端的Web应用，将客户端发送过来的用户ID和密码与之前登录过的信息做匹配来进行认证的。但鉴于HTTP是无状态协议，之前已认证成功的用户状态无法通过协议层面保存下来。即，无法实现状态管理，因此即使当该用户下一次继续访问，也无法区分他与其他的用户。于是我们会使用Cookie来管理Session，以弥补HTTP协议中不存在的状态管理功能

- Session管理及Cookie状态管理示意图

  ![epub_907764_193.jpeg](/image/图解HTTP/5e55b586420671e8aef78c33cbb15d2bf66884ab.jpeg)

- Session管理及Cookie状态管理

  - 步骤1：客户端把用户ID和密码等登录信息放入报文的实体部分，通常是以POST方法把请求发送给服务器。而这时，会使用HTTPS通信来进行HTML表单画面的显示和用户输入数据的发送

  - 步骤2：服务器会发放用以识别用户的Session ID。通过验证从客户端发送过来的登录信息进行身份认证，然后把用户的认证状态与Session ID绑定后记录在服务器端

    - 向客户端返回响应时，会在首部字段Set-Cookie内写入SessionID（如PHPSESSID=028a8c…）

    - 你可以把Session ID想象成一种用以区分不同用户的等位号。然而，如果Session ID被第三方盗走，对方就可以伪装成你的身份进行恶意操作了。因此必须防止Session ID被盗，或被猜出。为了做到这点，Session ID应使用难以推测的字符串，且服务器端也需要进行有效期的管理，保证其安全性

    - 另外，为减轻跨站脚本攻击（XSS）造成的损失，建议事先在Cookie内加上httponly属性

  - 步骤3：客户端接收到从服务器端发来的Session ID后，会将其作为Cookie保存在本地。下次向服务器发送请求时，浏览器会自动发送Cookie，所以Session ID也随之发送到服务器。服务器端可通过验证接收到的Session ID识别用户和其认证状态

- 另外，不仅基于表单认证的登录信息及认证过程都无标准化的方法，服务器端应如何保存用户提交的密码等登录信息等也没有标准化

  - 通常，一种安全的保存方法是，先利用给密码加盐（salt）[插图]的方式增加额外信息，再使用散列（hash）函数计算出散列值后保存。但是我们也经常看到直接保存明文密码的做法，而这样的做法具有导致密码泄露的风险
  - salt其实就是由服务器随机生成的一个字符串，但是要保证长度足够长，并且是真正随机生成的。然后把它和密码字符串相连接（前后都可以）生成散列值。当两个用户使用了同一个密码时，由于随机生成的salt值不同，对应的散列值也将是不同的。这样一来，很大程度上减少了密码特征，攻击者也就很难利用自己手中的密码特征库进行破解。——译者注

## 第九章 基于HTTP的功能追加协议

- 为何HTTP协议受众如此广泛？本章讲解了几个与HTTP相关联的协议使用案例。为什么HTTP协议受众能够如此广泛呢？

  - 过去，新编写接入互联网的系统或软件时，还需要同时编写实现与必要功能对应的新协议。但最近，使用HTTP的系统和软件占了绝大多数

  - 这有着诸多原因，其中与企业或组织的防火墙设定有着莫大的关系。防火墙的基本功能就是禁止非指定的协议和端口号的数据包通过。因此如果使用新协议或端口号则必须修改防火墙设置

  - 互联网上，使用率最高的当属Web。不管是否具备访问FTP和SSH的权限，一般公司都会开放对Web的访问。Web是基于HTTP协议运作的，因此在构建Web服务器或访问Web站点时，需事先设置防火墙HTTP（80/tcp）和HTTPS（443/tcp）的权限

  - 许多公司或组织已设定权限将HTTP作为通信环境，因此无须再修改防火墙的设定。可见HTTP具有导入简单这一大优势。而这也是基于HTTP服务或内容不断增加的原因之一

  - 还有一些其他原因，比如，作为HTTP客户端的浏览器已相当普遍，HTTP服务器的数量已颇具规模，HTTP本身就是优异的应用等

### 9.1 基于HTTP的协议

- 在建立HTTP标准规范时，制订者主要想把HTTP当作传输HTML文档的协议。随着时代的发展，Web的用途更具多样性，比如演化成在线购物网站、SNS（Social Networking Service，社交网络服务）、企业或组织内部的各种管理工具，等等

- 而这些网站所追求的功能可通过Web应用和脚本程序实现。即使这些功能已经满足需求，在性能上却未必最优，这是因为HTTP协议上的限制以及自身性能有限

- HTTP功能上的不足可通过创建一套全新的协议来弥补。可是目前基于HTTP的Web浏览器的使用环境已遍布全球，因此无法完全抛弃HTTP。有一些新协议的规则是基于HTTP的，并在此基础上添加了新的功能

#### 9.2 消除HTTP瓶颈的SPDY

- Google在2010年发布了SPDY（取自SPeeDY，发音同speedy），其开发目标旨在解决HTTP的性能瓶颈，缩短Web页面的加载时间（50%）

#### 9.2.1 HTTP的瓶颈

- 对于Facebook等社交网站，为了尽可能实时地显示更新的内容，服务器上一有内容更新，就需要直接把那些内容反馈到客户端的界面上。虽然看起来挺简单的，但HTTP却无法妥善地处理好这项任务

- 使用HTTP协议探知服务器上是否有内容更新，就必须频繁地从客户端到服务器端进行确认。如果服务器上没有内容更新，那么就会产生徒劳的通信

- 若想在现有Web实现所需的功能，以下这些HTTP标准就会成为瓶颈

  - 一条连接上只可发送一个请求

  - 请求只能从客户端开始。客户端不可以接收除响应以外的指令

  - 请求/响应首部未经压缩就发送。首部信息越多延迟越大

  - 发送冗长的首部。每次互相发送相同的首部造成的浪费较多

  - 可任意选择数据压缩格式。非强制压缩发送

- Ajax的解决方法

  - Ajax（Asynchronous JavaScript and XML，异步JavaScript与XML技术）是一种有效利用JavaScript和DOM（Document Object Model，文档对象模型）的操作，以达到局部Web页面替换加载的异步通信手段。和以前的同步通信相比，由于它只更新一部分页面，响应中传输的数据量会因此而减少，这一优点显而易见

  - Ajax的核心技术是名为XMLHttpRequest的API，通过JavaScript脚本语言的调用就能和服务器进行HTTP通信。借由这种手段，就能从已加载完毕的Web页面上发起请求，只更新局部页面

  - 而利用Ajax实时地从服务器获取内容，有可能会导致大量请求产生。另外，Ajax仍未解决HTTP协议本身存在的问题

- Comet的解决方法

  - 一旦服务器端有内容更新了，Comet不会让请求等待，而是直接给客户端返回响应。这是一种通过延迟应答，模拟实现服务器端向客户端推送（ServerPush）的功能

  - 通常，服务器端接收到请求，在处理完毕后就会立即返回响应，但为了实现推送功能，Comet会先将响应置于挂起状态，当服务器端有内容更新时，再返回该响应。因此，服务器端一旦有更新，就可以立即反馈给客户端

  - 内容上虽然可以做到实时更新，但为了保留响应，一次连接的持续时间也变长了。期间，为了维持连接会消耗更多的资源。另外，Comet也仍未解决HTTP协议本身存在的问题

- SPDY

  - 陆续出现的Ajax和Comet等提高易用性的技术，一定程度上使HTTP得到了改善，但HTTP协议本身的限制也令人有些束手无策。为了进行根本性的改善，需要有一些协议层面上的改动。SPDY协议，正是为了在协议级别消除HTTP所遭遇的瓶颈

#### 9.2.2 SPDY的设计与功能

- SPDY没有完全改写HTTP协议，而是在TCP/IP的应用层与传输层之间通过新加会话层的形式运作。同时，考虑到安全性问题，SPDY规定通信中使用SSL

- SPDY以会话层的形式加入，控制对数据的流动，但还是采用HTTP建立通信连接。因此，可照常使用HTTP的GET和POST等方法、Cookie以及HTTP报文等

- SPDY的设计

  ![epub_907764_199.jpeg](/image/图解HTTP/ee15244af05cbebc845dd43b455d7e629a6b6c19.jpeg)

- 使用SPDY后，HTTP协议额外获得以下功能

  - 多路复用流：通过单一的TCP连接，可以无限制处理多个HTTP请求。所有请求的处理都在一条TCP连接上完成，因此TCP的处理效率得到提高

  - 赋予请求优先级：SPDY不仅可以无限制地并发处理请求，还可以给请求逐个分配优先级顺序。这样主要是为了在发送多个请求时，解决因带宽低而导致响应变慢的问题

  - 压缩HTTP首部压缩：HTTP请求和响应的首部。这样一来，通信产生的数据包数量和发送的字节数就更少了

  - 推送功能：支持服务器主动向客户端推送数据的功能。这样，服务器可直接发送数据，而不必等待客户端的请求

  - 服务器提示功能：服务器可以主动提示客户端请求所需的资源。由于在客户端发现资源之前就可以获知资源的存在，因此在资源已缓存等情况下，可以避免发送不必要的请求

#### 9.2.3 SPDY消除Web瓶颈了吗

- 希望使用SPDY时，Web的内容端不必做什么特别改动，而Web浏览器及Web服务器都要为对应SPDY做出一定程度上的改动。有好几家Web浏览器已经针对SPDY做出了相应的调整。另外，Web服务器也进行了实验性质的应用，但把该技术导入实际的Web网站却进展不佳

- 因为SPDY基本上只是将单个域名（IP地址）的通信多路复用，所以当一个Web网站上使用多个域名下的资源，改善效果就会受到限制

- SPDY的确是一种可有效消除HTTP瓶颈的技术，但很多Web网站存在的问题并非仅仅是由HTTP瓶颈所导致。对Web本身的速度提升，还应该从其他可细致钻研的地方入手，比如改善Web内容的编写方式等

### 9.3 使用浏览器进行全双工通信的WebSocket

- 利用Ajax和Comet技术进行通信可以提升Web的浏览速度。但问题在于通信若使用HTTP协议，就无法彻底解决瓶颈问题。WebSocket网络技术正是为解决这些问题而实现的一套新协议及API

- 当时筹划将WebSocket作为HTML5标准的一部分，而现在它却逐渐变成了独立的协议标准。WebSocket通信协议在2011年12月11日，被RFC 6455- TheWebSocket Protocol定为标准

#### 9.3.1 WebSocket的设计与功能

- WebSocket，即Web浏览器与Web服务器之间全双工通信标准。其中，WebSocket协议由IETF定为标准，WebSocket API由W3C定为标准

- 仍在开发中的WebSocket技术主要是为了解决Ajax和Comet里XMLHttpRequest附带的缺陷所引起的问题

#### 9.3.2 WebSocket协议

- 一旦Web服务器与客户端之间建立起WebSocket协议的通信连接，之后所有的通信都依靠这个专用协议进行。通信过程中可互相发送JSON、XML、HTML或图片等任意格式的数据

- 由于是建立在HTTP基础上的协议，因此连接的发起方仍是客户端，而一旦确立WebSocket通信连接，不论服务器还是客户端，任意一方都可直接向对方发送报文

- 下面我们列举一下WebSocket协议的主要特点

  - 推送功能：支持由服务器向客户端推送数据的推送功能。这样，服务器可直接发送数据，而不必等待客户端的请求

  - 减少通信量：只要建立起WebSocket连接，就希望一直保持连接状态。和HTTP相比，不但每次连接时的总开销减少，而且由于WebSocket的首部信息很小，通信量也相应减少了

- 为了实现WebSocket通信，在HTTP连接建立之后，需要完成一次“握手”（Handshaking）的步骤

- 为了实现WebSocket通信，需要用到HTTP的Upgrade首部字段，告知服务器通信协议发生改变，以达到握手的目的，同时还有其他的一些首部字段

  - 示例

    ```http
    UPgrade: websocket
    ```

  - Sec-WebSocket-Key字段内记录着握手过程中必不可少的键值。Sec-WebSocket-Protocol字段内记录使用的子协议。子协议按WebSocket协议标准在连接分开使用时，定义那些连接的名称

- 对于之前的请求，返回状态码101 Switching Protocols的响应确定建立websocket链接，同时还有其他的一些首部字段

  - Sec-WebSocket-Accept的字段值是由握手请求中的Sec-WebSocket-Key的字段值生成的

- 成功握手确立WebSocket连接之后，通信时不再使用HTTP的数据帧，而采用WebSocket独立的数据帧

- WebSocket通信

  ![epub_907764_200.jpeg](/image/图解HTTP/ad9c361a867be1b497edb59b21712c8d5a44b7ad.jpeg)

- JavaScript可调用“The WebSocket API”（http://www.w3.org/TR/websockets/，由W3C标准制定）内提供的WebSocket程序接口，以实现WebSocket协议下全双工通信

### 9.4 期盼已久的HTTP/2.0

- 目前主流的HTTP/1.1标准，自1999年发布的RFC2616之后再未进行过改订。SPDY和WebSocket等技术纷纷出现，很难断言HTTP/1.1仍是适用于当下的Web的协议

- 负责互联网技术标准的IETF（Internet Engineering Task Force，互联网工程任务组）创立httpbis（Hypertext Transfer ProtocolBis,http://datatracker.ietf.org/wg/httpbis/）工作组，其目标是推进下一代HTTP——HTTP/2.0在2014年11月实现标准化

- HTTP/2.0的目标是改善用户在使用Web时的速度体验。由于基本上都会先通过HTTP/1.1与TCP连接，现在我们以下面的这些协议为基础，探讨一下它们的实现方法

  - SPDY

  - HTTP Speed+Mobility：HTTP Speed+Mobility由微软公司起草，是用于改善并提高移动端通信时的通信速度和性能的标准。它建立在Google公司提出的SPDY与WebSocket的基础之上

  - Network-Friendly HTTP Upgrade：Network-Friendly HTTP Upgrade主要是在移动端通信时改善HTTP性能的标准

- HTTP/2.0围绕着主要的7项技术进行讨论，现阶段（2012年8月13日），大都倾向于采用以下协议的技术。但是，讨论仍在持续，所以不能排除会发生重大改变的可能性

  ![epub_907764_201.jpeg](/image/图解HTTP/d7b718ae32b718d2a3bf42fb1b4ac31f95948bc9.jpeg)

### 9.5 Web服务器管理文件的WebDAV

- WebDAV（Web-based Distributed Authoring and Versioning，基于万维网的分布式创作和版本控制）是一个可对Web服务器上的内容直接进行文件复制、编辑等操作的分布式文件系统。它作为扩展HTTP/1.1的协议定义在RFC4918

- 除了创建、删除文件等基本功能，它还具备文件创建者管理、文件编辑过程中禁止其他用户内容覆盖的加锁功能，以及对文件内容修改的版本控制功能

- 使用HTTP/1.1的PUT方法和DELETE方法，就可以对Web服务器上的文件进行创建和删除操作。可是出于安全性及便捷性等考虑，一般不使用

- WebDAV

  ![epub_907764_202.jpeg](/image/图解HTTP/d96943ef4ab4725a7172a892f575779053d6edbd.jpeg)

#### 9.5.1 扩展HTTP/1.1的WebDAV

- 针对服务器上的资源，WebDAV新增加了一些概念，如下所示

  - 集合（Co lection）：是一种统一管理多个资源的概念。以集合为单位可进行各种操作。也可实现类似集合的集合这样的叠加

  - 资源（Resource）：把文件或集合称为资源

  - 属性（Property）：定义资源的属性。定义以“名称=值”的格式执行

  - 锁（Lock）：把文件设置成无法编辑状态。多人同时编辑时，可防止在同一时间进行内容写入

#### 9.5.2 WebDAV内新增的方法及状态码

- WebDAV为实现远程文件管理，向HTTP/1.1中追加了以下这些方法

  - PROPFIND：获取属性

  - PROPPATCH：修改属性

  - MKCOL：创建集合

  - COPY：复制资源及属性

  - MOVE：移动资源

  - LOCK：资源加锁

  - UNLOCK：资源解锁

- 为配合扩展的方法，状态码也随之扩展

  - 102 Processing：可正常处理请求，但目前是处理中状态

  - 207 Multi-Status：存在多种状态

  - 422 Unprocessible Entity：格式正确，内容有误

  - 423 Locked：资源已被加锁

  - 424 Failed Dependency：处理与某请求关联的请求失败，因此不再维持依赖关系

  - 507 Insufficient Storage：保存空间不足

## 第十章 构建Web内容的技术

### 10.1 HTML

#### 10.1.1 Web页面几乎全由HTML构建

- HTML（HyperText Markup Language，超文本标记语言）是为了发送Web上的超文本（Hypertext）而开发的标记语言
  - 超文本是一种文档系统，可将文档中任意位置的信息与其他信息（文本或图片等）建立关联，即超链接文本
  - 标记语言是指通过在文档的某部分穿插特别的字符串标签，用来修饰文档的语言。我们把出现在HTML文档内的这种特殊字符串叫做HTML标签（Tag）
- 平时我们浏览的Web页面几乎全是使用HTML写成的。由HTML构成的文档经过浏览器的解析、渲染后，呈现出来的结果就是Web页面

#### 10.1.2 HTML的版本

- Tim Berners-Lee提出HTTP概念的同时，还提出了HTML原型。1993年在伊利诺伊大学的NCSA（The National Center for SupercomputingApplications，国家超级计算机应用中心）发布了Mosaic浏览器（世界首个图形界面浏览器程序），而能够被Mosaic解析的HTML，统一标准后即作为HTML 1.0发布

- 目前的最新版本是HTML4.01标准（2013年），1999年12月W3C（World Wide WebConsortium）组织推荐使用这一版本。下一个版本，预计会在2014年左右正式推荐使用HTML5标准

- HTML5标准不仅解决了浏览器之间的兼容性问题，并且可把文本作为数据对待，更容易复用，动画等效果也变得更生动

- 时至今日，HTML仍存在较多悬而未决问题。有些浏览器未遵循HTML标准实现，或扩展自用标签等，这都反映了HTML的标准实际上尚未统一这一现状

#### 10.1.3 设计应用CSS

- CSS（Cascading Style Sheets，层叠样式表）可以指定如何展现HTML内的各种元素，属于样式表标准之一。即使是相同的HTML文档，通过改变应用的CSS，用浏览器看到的页面外观也会随之改变。CSS的理念就是让文档的结构和设计分离，达到解耦的目的

### 10.2 动态HTML

#### 10.2.1 让Web页面动起来的动态HTML

- 所谓动态HTML（Dynamic HTML），是指使用客户端脚本语言将静态的HTML内容变成动态的技术的总称。鼠标单击点开的新闻、Google Maps等可滚动的地图就用到了动态HTML

- 动态HTML技术是通过调用客户端脚本语言JavaScript，实现对HTML的Web页面的动态改造。利用DOM（Document Object Model，文档对象模型）可指定欲发生动态变化的HTML元素

#### 10.2.2 更易控制HTML的DOM

- DOM是用以操作HTML文档和XML文档的API（Application ProgrammingInterface，应用编程接口）。使用DOM可以将HTML内的元素当作对象操作，如取出元素内的字符串、改变那个CSS的属性等，使页面的设计发生改变

- 通过调用JavaScript等脚本语言对DOM的操作，可以以更为简单的方式控制HTML的改变

### 10.3 Web应用

#### 10.3.1 通过Web提供功能的Web应用

- Web应用是指通过Web功能提供的应用程序。比如购物网站、网上银行、SNS、BBS、搜索引擎和e-learning等。互联网（Internet）或企业内网（Intranet）上遍布各式各样的Web应用

- 原本应用HTTP协议的Web的机制就是对客户端发来的请求，返回事前准备好的内容。可随着Web越来越普及，仅靠这样的做法已不足以应对所有的需求，更需要引入由程序创建HTML内容的做法

- 类似这种由程序创建的内容称为动态内容，而事先准备好的内容称为静态内容。Web应用则作用于动态内容之上

#### 10.3.2 与Web服务器及程序协作的CGI

- CGI（Common Gateway Interface，通用网关接口）是指Web服务器在接收到客户端发送过来的请求后转发给程序的一组机制。在CGI的作用下，程序会对请求内容做出相应的动作，比如创建HTML等动态内容

- 使用CGI的程序叫做CGI程序，通常是用Perl、PHP、Ruby和C等编程语言编写而成

- 有关CGI更为翔实的内容请参考RFC3875“The Common Gateway Interface(CGI) Version 1.1”

- CGI

  ![epub_907764_207.jpeg](/image/图解HTTP/d980b9d122d22a4b84357deedbec1e15d785dad9.jpeg)

#### 10.3.3 因Java而普及的Servlet

- Servlet是一种能在服务器上创建动态内容的程序。Servlet是用Java语言实现的一个接口，属于面向企业级Java（JavaEE,Java Enterprise Edition）的一部分

- 之前提及的CGI，由于每次接到请求，程序都要跟着启动一次。因此一旦访问量过大，Web服务器要承担相当大的负载。而Servlet运行在与Web服务器相同的进程中，因此受到的负载较小。Servlet的运行环境叫做Web容器或Servlet容器

- Servlet作为解决CGI问题的对抗技术，随Java一起得到了普及

  ![epub_907764_211.jpeg](/image/图解HTTP/7e181f8984b4466d7c7d860c7648d5b5c9b7d2d9.jpeg)

- 随着CGI的普及，每次请求都要启动新CGI程序的CGI运行机制逐渐变成了性能瓶颈，所以之后Servlet和mod_perl等可直接在Web服务器上运行的程序才得以开发、普及

### 10.4 数据发布的格式及语言

#### 10.4.1 可扩展标记语言

- XML（eXtensible Markup Language，可扩展标记语言）是一种可按应用目标进行扩展的通用标记语言。旨在通过使用XML，使互联网数据共享变得更容易

- XML和HTML都是从标准通用标记语言SGML（Standard Generalized MarkupLanguage）简化而成。与HTML相比，它对数据的记录方式做了特殊处理

- XML和HTML一样，使用标签构成树形结构，并且可自定义扩展标签。从XML文档中读取数据比起HTML更为简单。由于XML的结构基本上都是用标签分割而成的树形结构，因此通过语法分析器（Parser）的解析功能解析XML结构并取出数据元素，可更容易地对数据进行读取

- 更容易地复用数据使得XML在互联网上被广泛接受。比如，可用在2个不同的应用之间的交换数据格式化

#### 10.4.2 发布更新信息的RSS/Atom

- RSS（简易信息聚合，也叫聚合内容）和Atom都是发布新闻或博客日志等更新信息文档的格式的总称。两者都用到了XML

- RSS有以下版本，名称和编写方式也不相同

  - RSS 0.9（RDF Site Summary）：最初的RSS版本。1999年3月由网景通信公司自行开发用于其门户网站。基础构图创建在初期的RDF规格上

  - RSS 0.91（Rich Site Summary）：在RSS0.9的基础上扩展元素，于1999年7月开发完毕。非RDF规格，使用XML方式编写

  - RSS 1.0（RDF Site Summary）:RSS规格正处于混乱状态。2000年12月由RSS-DEV工作组再次采用RSS0.9中使用的RDF规格发布

  - RSS2.0（Really Simple Syndication）：非RSS1.0发展路线。增加支持RSS0.91的兼容性，2000年12月由UserLand Software公司开发完成

- Atom具有以下两种标准

  - Atom供稿格式（Atom Syndication Format）：为发布内容而制定的网站消息来源格式，单讲Atom时，就是指此标准

  - Atom出版协定（Atom Publishing Protocol）：为Web上内容的新增或修改而制定的协议

- 用于订阅博客更新信息的RSS阅读器，这种应用几乎支持RSS的所有版本以及Atom

#### 10.4.3 JavaScript衍生的轻量级易用JSON

- JSON（JavaScript Object Notation）是一种以JavaScript（ECMAScript）的对象表示法为基础的轻量级数据标记语言。能够处理的数据类型有false/null/true/对象/数组/数字/字符串，这7种类型

- JSON让数据更轻更纯粹，并且JSON的字符串形式可被JavaScript轻易地读入。当初配合XML使用的Ajax技术也让JSON的应用变得更为广泛。另外，其他各种编程语言也提供丰富的库类，以达到轻便操作JSON的目的

## 第十一章 Web的攻击技术

- 简单的HTTP协议本身并不存在安全性问题，因此协议本身几乎不会成为攻击的对象。应用HTTP协议的服务器和客户端，以及运行在服务器上的Web应用等资源才是攻击目标

#### 11.1.1 HTTP不具备必要的安全功能

- 与最初的设计相比，现今的Web网站应用的HTTP协议的使用方式已发生了翻天覆地的变化。几乎现今所有的Web网站都会使用会话（session）管理、加密处理等安全性方面的功能，而HTTP协议内并不具备这些功能

- 从整体上看，HTTP就是一个通用的单纯协议机制。因此它具备较多优势，但是在安全性方面则呈劣势

- 就拿远程登录时会用到的SSH协议来说，SSH具备协议级别的认证及会话管理等功能，HTTP协议则没有。另外在架设SSH服务方面，任何人都可以轻易地创建安全等级高的服务，而HTTP即使已架设好服务器，但若想提供服务器基础上的Web应用，很多情况下都需要重新开发

- 因此，开发者需要自行设计并开发认证及会话管理功能来满足Web应用的安全。而自行设计就意味着会出现各种形形色色的实现。结果，安全等级并不完备，可仍在运作的Web应用背后却隐藏着各种容易被攻击者滥用的安全漏洞的Bug

#### 11.1.2 在客户端即可篡改请求

- 在Web应用中，从浏览器那接收到的HTTP请求的全部内容，都可以在客户端自由地变更、篡改。所以Web应用可能会接收到与预期数据不相同的内容

- 在HTTP请求报文内加载攻击代码，就能发起对Web应用的攻击。通过URL查询字段或表单、HTTP首部、Cookie等途径把攻击代码传入，若这时Web应用存在安全漏洞，那内部信息就会遭到窃取，或被攻击者拿到管理权限

#### 11.1.3 针对Web应用的攻击模式

- 对Web应用的攻击模式有以下两种

  - 主动攻击

  - 被动攻击

- 以服务器为目标的主动攻击

  - 主动攻击（active attack）是指攻击者通过直接访问Web应用，把攻击代码传入的攻击模式。由于该模式是直接针对服务器上的资源进行攻击，因此攻击者需要能够访问到那些资源

  - 主动攻击模式里具有代表性的攻击是SQL注入攻击和OS命令注入攻击

- 以服务器为目标的被动攻击

  - 被动攻击（passive attack）是指利用圈套策略执行攻击代码的攻击模式。在被动攻击过程中，攻击者不直接对目标Web应用访问发起攻击

  - 被动攻击通常的攻击模式如下所示

    - 步骤1： 攻击者诱使用户触发已设置好的陷阱，而陷阱会启动发送已嵌入攻击代码的HTTP请求

    - 步骤2： 当用户不知不觉中招之后，用户的浏览器或邮件客户端就会触发这个陷阱

    - 步骤3： 中招后的用户浏览器会把含有攻击代码的HTTP请求发送给作为攻击目标的Web应用，运行攻击代码

    - 步骤4： 执行完攻击代码，存在安全漏洞的Web应用会成为攻击者的跳板，可能导致用户所持的Cookie等个人信息被窃取，登录状态中的用户权限遭恶意滥用等后果

- 利用被动攻击，可发起对原本从互联网上无法直接访问的企业内网等网络的攻击。只要用户踏入攻击者预先设好的陷阱，在用户能够访问到的网络范围内，即使是企业内网也同样会受到攻击

### 11.2 因输出值转义不完全引发的安全漏洞

- 实施Web应用的安全对策可大致分为以下两部分

  - 客户端的验证

  - Web应用端（服务器端）的验证

- 验证数据的几个地方

  ![epub_907764_218.jpeg](/image/图解HTTP/51553b4aa2206040b099bf95b4bcdfbf05b26c15.jpeg)

- 多数情况下采用JavaScript在客户端验证数据。可是在客户端允许篡改数据或关闭JavaScript，不适合将JavaScript验证作为安全的防范对策。保留客户端验证只是为了尽早地辨识输入错误，起到提高UI体验的作用

- Web应用端的输入值验证按Web应用内的处理则有可能被误认为是具有攻击性意义的代码。输入值验证通常是指检查是否是符合系统业务逻辑的数值或检查字符编码等预防对策

- 从数据库或文件系统、HTML、邮件等输出Web应用处理的数据之际，针对输出做值转义处理是一项至关重要的安全策略。当输出值转义不完全时，会因触发攻击者传入的攻击代码，而给输出对象带来损害

#### 11.2.1 跨站脚本攻击

- 跨站脚本攻击（Cross-Site Scripting,XSS）是指通过存在安全漏洞的Web网站注册用户的浏览器内运行非法的HTML标签或JavaScript进行的一种攻击。动态创建的HTML部分有可能隐藏着安全漏洞。就这样，攻击者编写脚本设下陷阱，用户在自己的浏览器上运行时，一不小心就会受到被动攻击

- 跨站脚本攻击有可能造成以下影响

  - 利用虚假输入表单骗取用户个人信息

  - 利用脚本窃取用户的Cookie值，被害者在不知情的情况下，帮助攻击者发送恶意请求

  - 显示伪造的文章或图片

#### 11.2.2 SQL注入攻击

- SQL注入（SQL Injection）是指针对Web应用使用的数据库，通过运行非法的SQL而产生的攻击。该安全隐患有可能引发极大的威胁，有时会直接导致个人信息及机密信息的泄露

- Web应用通常都会用到数据库，当需要对数据库表内的数据进行检索或添加、删除等操作时，会使用SQL语句连接数据库进行特定的操作。如果在调用SQL语句的方式上存在疏漏，就有可能执行被恶意注入（Injection）非法SQL语句

- SQL注入攻击有可能会造成以下等影响

  - 非法查看或篡改数据库内的数据

  - 规避认证

  - 执行和数据库服务器业务关联的程序等

#### 11.2.3 OS命令注入攻击

- OS命令注入攻击（OS Command Injection）是指通过Web应用，执行非法的操作系统命令达到攻击的目的。只要在能调用Shell函数的地方就有存在被攻击的风险

- 可以从Web应用中通过Shell来调用操作系统命令。倘若调用Shell时存在疏漏，就可以执行插入的非法OS命令

- OS命令注入攻击可以向Shell发送命令，让Windows或Linux操作系统的命令行启动程序。也就是说，通过OS注入攻击可执行OS上安装着的各种程序

#### 11.2.4 HTTP首部注入攻击

- HTTP首部注入攻击（HTTP Header Injection）是指攻击者通过在响应首部字段内插入换行，添加任意响应首部或主体的一种攻击。属于被动攻击模式

- 向首部主体内添加内容的攻击称为HTTP响应截断攻击（HTTP ResponseSplitting Attack）

- HTTP首部注入攻击有可能会造成以下一些影响

  - 设置任何Cookie信息

  - 重定向至任意URL

  - 显示任意的主体（HTTP响应截断攻击）

- HTTP响应截断攻击是用在HTTP首部注入的一种攻击。攻击顺序相同，但是要将两个%0D%0A%0D%0A并排插入字符串后发送。利用这两个连续的换行就可作出HTTP首部与主体分隔所需的空行了，这样就能显示伪造的主体，达到攻击目的。这样的攻击叫做HTTP响应截断攻击

- 另外，滥用HTTP/1.1中汇集多响应返回功能，会导致缓存服务器对任意内容进行缓存操作。这种攻击称为缓存污染。使用该缓存服务器的用户，在浏览遭受攻击的网站时，会不断地浏览被替换掉的Web网页

#### 11.2.5 邮件首部注入攻击

- 邮件首部注入（Mail Header Injection）是指Web应用中的邮件发送功能，攻击者通过向邮件首部To或Subject内任意添加非法内容发起的攻击。利用存在安全漏洞的Web网站，可对任意邮件地址发送广告邮件或病毒邮件

#### 11.2.6 目录遍历攻击

- 目录遍历（Directory Traversal）攻击是指对本无意公开的文件目录，通过非法截断其目录路径后，达成访问目的的一种攻击。这种攻击有时也称为路径遍历（Path Traversal）攻击

- 通过Web应用对文件处理操作时，在由外部指定文件名的处理存在疏漏的情况下，用户可使用．../等相对路径定位到/etc/passed等绝对路径上，因此服务器上任意的文件或文件目录皆有可能被访问到。这样一来，就有可能非法浏览、篡改或删除Web服务器上的文件

- 固然存在输出值转义的问题，但更应该关闭指定对任意文件名的访问权限

#### 11.2.7 远程文件包含漏洞

- 远程文件包含漏洞（Remote File Inclusion）是指当部分脚本内容需要从其他文件读入时，攻击者利用指定外部服务器的URL充当依赖文件，让脚本读取之后，就可运行任意脚本的一种攻击

- 这主要是PHP存在的安全漏洞，对PHP的include或require来说，这是一种可通过设定，指定外部服务器的URL作为文件名的功能。但是，该功能太危险，PHP5.2.0之后默认设定此功能无效

- 固然存在输出值转义的问题，但更应控制对任意文件名的指定

### 11.3 因设置或设计上的缺陷引发的安全漏洞

- 因设置或设计上的缺陷引发的安全漏洞是指，错误设置Web服务器，或是由设计上的一些问题引起的安全漏洞

#### 11.3.1 强制浏览

- 强制浏览（Forced Browsing）安全漏洞是指，从安置在Web服务器的公开目录下的文件中，浏览那些原本非自愿公开的文件

- 强制浏览有可能会造成以下一些影响

  - 泄露顾客的个人信息等重要情报

  - 泄露原本需要具有访问权限的用户才可查阅的信息内容

  - 泄露未外连到外界的文件

- 对那些原本不愿公开的文件，为了保证安全会隐蔽其URL。可一旦知道了那些URL，也就意味着可浏览URL对应的文件。直接显示容易推测的文件名或文件目录索引时，通过某些方法可能会使URL产生泄露

- 示例

  - 文件目录一览：

    - http://www.example.com/log/

    - 通过指定文件目录名称，即可在文件一览中看到显示的文件名

  - 容易被推测的文件名及目录名

    - http://www.example.com/entry/entry_081202.log

    - 文件名称容易推测（按上面的情况，可推出下一个文件是entry_081203.log）

  - 备份文件

    - http://www.example.com/cgi-bin/entry.cgi（原始文件）

    - http://www.example.com/cgi-bin/entry.cgi～（备份文件）

    - http://www.example.com/cgi-bin/entry.bak（备份文件）

#### 11.3.2 不正确的错误消息处理

- 不正确的错误消息处理（Error Handling Vulnerability）的安全漏洞是指，Web应用的错误信息内包含对攻击者有用的信息。与Web应用有关的主要错误信息如下所示

  - Web应用抛出的错误消息

  - 数据库等系统抛出的错误消息

- Web应用不必在用户的浏览画面上展现详细的错误消息。对攻击者来说，详细的错误消息有可能给他们下一次攻击以提示

- 系统抛出的错误主要集中在以下几个方面

  - PHP或ASP等脚本错误

  - 数据库或中间件的错误

  - Web服务器的错误

- 各系统应对详细的错误消息进行抑制设定，或使用自定义错误消息，以避免某些错误信息给攻击者以启发

#### 11.3.3 开放重定向

- 开放重定向（Open Redirect）是一种对指定的任意URL作重定向跳转的功能。而与此功能相关联的安全漏洞是指，假如指定的重定向URL到某个具有恶意的Web网站，那么用户就会被诱导至那个Web网站

### 11.4 因会话管理疏忽引发的安全漏洞

- 会话管理是用来管理用户状态的必备功能，但是如果在会话管理上有所疏忽，就会导致用户的认证状态被窃取等后果

#### 11.4.1 会话劫持

- 会话劫持（Session Hijack）是指攻击者通过某种手段拿到了用户的会话ID，并非法使用此会话ID伪装成用户，达到攻击的目的

- 具备认证功能的Web应用，使用会话ID的会话管理机制，作为管理认证状态的主流方式。会话ID中记录客户端的Cookie等信息，服务器端将会话ID与认证状态进行一对一匹配管理

- 下面列举了几种攻击者可获得会话ID的途径。

  - 通过非正规的生成方法推测会话ID

  - 通过窃听或XSS攻击盗取会话ID

  - 通过会话固定攻击（Session Fixation）强行获取会话ID

#### 11.4.2 会话固定攻击

- 对以窃取目标会话ID为主动攻击手段的会话劫持而言，会话固定攻击（Session Fixation）攻击会强制用户使用攻击者指定的会话ID，属于被动攻击

- 会话固定攻击案例

  ![epub_907764_241.jpeg](/image/图解HTTP/d35e443ae990b38548d76802771da4e0245ffad8.jpeg)

- Session Adoption是指PHP或ASP.NET能够接收处理未知会话ID的功能。恶意使用该功能便可跳过会话固定攻击的准备阶段，从Web网站获得发行的会话ID的步骤。即，攻击者可私自创建会话ID构成陷阱，中间件却会误以为该会话ID是未知会话ID而接受

#### 11.4.3 跨站点请求伪造

- 跨站点请求伪造（Cross-Site Request Forgeries,CSRF）攻击是指攻击者通过设置好的陷阱，强制对已完成认证的用户进行非预期的个人信息或设定信息等某些状态更新，属于被动攻击

- 跨站点请求伪造有可能会造成以下等影响

  - 利用已通过认证的用户权限更新设定信息等

  - 利用已通过认证的用户权限购买商品

  - 利用已通过认证的用户权限在留言板上发表言论

### 11.5 其他安全漏洞

#### 11.5.1 密码破解

- 密码破解攻击（Password Cracking）即算出密码，突破认证。攻击不仅限于Web应用，还包括其他的系统（如FTP或SSH等）

- 密码破解有以下两种手段

  - 通过网络的密码试错

  - 对已加密密码的破解（指攻击者入侵系统，已获得加密或散列处理的密码数据的情况）

- 除去突破认证的攻击手段，还有SQL注入攻击逃避认证，跨站脚本攻击窃取密码信息等方法

- 通过网络进行密码试错：对Web应用提供的认证功能，通过网络尝试候选密码进行的一种攻击。主要有以下两种方式

  - 穷举法

    - 穷举法（Brute-force Attack，又称暴力破解法）是指对所有密钥集合构成的密钥空间（Keyspace）进行穷举。即，用所有可行的候选密码对目标的密码系统试错，用以突破验证的一种攻击

    - 因为穷举法会尝试所有的候选密码，所以是一种必然能够破解密码的攻击。但是，当密钥空间很庞大时，解密可能需要花费数年，甚至千年的时间，因此从现实角度考量，攻击是失败的

  - 字典攻击

    - 字典攻击是指利用事先收集好的候选密码（经过各种组合方式后存入字典），枚举字典中的密码，尝试通过认证的一种攻击手法

    - 与穷举法相比，由于需要尝试的候选密码较少，意味着攻击耗费的时间比较短。但是，如果字典中没有正确的密码，那就无法破解成功。因此攻击的成败取决于字典的内容

- 对已加密密码的破解：Web应用在保存密码时，一般不会直接以明文的方式保存，通过散列函数做散列处理或加salt的手段对要保存的密码本身加密。那即使攻击者使用某些手段窃取密码数据，如果想要真正使用这些密码，则必须先通过解码等手段，把加密处理的密码还原成明文形式。从加密过的数据中导出明文通常有以下几种方法

  - 通过穷举法+字典攻击进行类推

    - 针对密码使用散列函数进行加密处理的情况，采用和穷举法或字典攻击相同的手法，尝试调用相同的散列函数加密候选密码，然后把计算出的散列值与目标散列值匹配，类推出密码

  - 彩虹表

    - 彩虹表（Rainbow Table）是由明文密码及与之对应的散列值构成的一张数据库表，是一种通过事先制作庞大的彩虹表，可在穷举法+字典攻击等实际破解过程中缩短消耗时间的技巧。从彩虹表内搜索散列值就可以推导出对应的明文密码

  - 拿到密钥

    - 使用共享密钥加密方式对密码数据进行加密处理的情况下，如果能通过某种手段拿到加密使用的密钥，也就可以对密码数据解密了

  - 加密算法的漏洞

    - 考虑到加密算法本身可能存在的漏洞，利用该漏洞尝试解密也是一种可行的方法。但是要找到那些已广泛使用的加密算法的漏洞，又谈何容易，因此困难极大，不易成功。而Web应用开发者独立实现的加密算法，想必尚未经过充分的验证，还是很有可能存在漏洞的

#### 11.5.2 点击劫持

- 点击劫持（Clickjacking）是指利用透明的按钮或链接做成陷阱，覆盖在Web页面之上。然后诱使用户在不知情的情况下，点击那个链接访问内容的一种攻击手段。这种行为又称为界面伪装（UI Redressing）

- 已设置陷阱的Web页面，表面上内容并无不妥，但早已埋入想让用户点击的链接。当用户点击到透明的按钮时，实际上是点击了已指定透明属性元素的iframe页面

#### 11.5.3 DoS攻击

- DoS攻击（Denial of Service attack）是一种让运行中的服务呈停止状态的攻击。有时也叫做服务停止攻击或拒绝服务攻击。DoS攻击的对象不仅限于Web网站，还包括网络设备及服务器等

- 主要有以下两种DoS攻击方式

  - 集中利用访问请求造成资源过载，资源用尽的同时，实际上服务也就呈停止状态

    - 其中，集中利用访问请求的DoS攻击，单纯来讲就是发送大量的合法请求。服务器很难分辨何为正常请求，何为攻击请求，因此很难防止DoS攻击

  - 通过攻击安全漏洞使服务停止

- 多台计算机发起的DoS攻击称为DDoS攻击（Distributed Denial of Serviceattack）。DDoS攻击通常利用那些感染病毒的计算机作为攻击者的攻击跳板

#### 11.5.4 后门程序

- 后门程序（Backdoor）是指开发设置的隐藏入口，可不按正常步骤使用受限功能。利用后门程序就能够使用原本受限制的功能

- 通常的后门程序分为以下3种类型

  - 开发阶段作为Debug调用的后门程序

  - 开发者为了自身利益植入的后门程序

  - 攻击者通过某种方法设置的后门程序

- 可通过监视进程和通信的状态发现被植入的后门程序。但设定在Web应用中的后门程序，由于和正常使用时区别不大，通常很难发现
